{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import shutil\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from keras.preprocessing import image\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.layers.core import Activation, Flatten, Dropout, Dense\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "import matplotlib.image as mpimg\n",
    "from sklearn.preprocessing import LabelBinarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "proportion = 0.1\n",
    "BATCH_SIZE = 20\n",
    "SIZE = 150\n",
    "default_image_size = tuple((128,128))\n",
    "EPOCH = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get train and val data\n",
    "data_train = os.listdir('tomato/train_lite/')\n",
    "data_val = os.listdir('tomato/test_lite/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a proportion of whole data\n",
    "for folder in data_train:\n",
    "    i = 0\n",
    "    for data in os.listdir('tomato/val/'+folder):\n",
    "        if(i < proportion * len(os.listdir('tomato/val/'+folder))):\n",
    "            shutil.copyfile('tomato/val/'+folder+'/'+data, 'tomato/test_lite/'+folder+'/'+data)\n",
    "            i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = 'tomato'\n",
    "\n",
    "train_dir = 'tomato/train_lite'\n",
    "test_dir = 'tomato/test_lite'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1000 images belonging to 10 classes.\n",
      "Found 100 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "# All images will be rescaled by 1./255.\n",
    "train_datagen = ImageDataGenerator( rescale = 1.0/255. )\n",
    "test_datagen  = ImageDataGenerator( rescale = 1.0/255. )\n",
    "\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(train_dir,\n",
    "                                                    batch_size=BATCH_SIZE,\n",
    "                                                    class_mode='categorical',\n",
    "                                                    target_size=(150, 150))     \n",
    "\n",
    "test_generator =  test_datagen.flow_from_directory(test_dir,\n",
    "                                                         batch_size=BATCH_SIZE,\n",
    "                                                         class_mode  = 'categorical',\n",
    "                                                         target_size = (150, 150))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#chanDim = -1\n",
    "model = tf.keras.models.Sequential([\n",
    "    # Note the input shape is the desired size of the image 150x150 with 3 bytes color\n",
    "    tf.keras.layers.Conv2D(128, (3,3), activation='relu', input_shape=(150, 150, 3)),\n",
    "    tf.keras.layers.MaxPooling2D(3,3),\n",
    "    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n",
    "    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2), \n",
    "    tf.keras.layers.Conv2D(128, (3,3), activation='relu'), \n",
    "    tf.keras.layers.Conv2D(128, (3,3), activation='relu'), \n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    # Flatten the results to feed into a DNN\n",
    "    tf.keras.layers.Flatten(), \n",
    "    # 512 neuron hidden layer\n",
    "    tf.keras.layers.Dense(1024, activation='relu'), \n",
    "    # Only 1 output neuron. It will contain a value from 0-1 where 0 for 1 class ('cats') and 1 for the other ('dogs')\n",
    "    tf.keras.layers.Dense(10, activation='softmax')  \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 148, 148, 128)     3584      \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 49, 49, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 47, 47, 128)       147584    \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 45, 45, 128)       147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 22, 22, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 20, 20, 128)       147584    \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 18, 18, 128)       147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 9, 9, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 10368)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1024)              10617856  \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                10250     \n",
      "=================================================================\n",
      "Total params: 11,222,026\n",
      "Trainable params: 11,222,026\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.Adam(),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "50/50 [==============================] - 109s 2s/step - loss: 2.3106 - accuracy: 0.0990 - val_loss: 2.3013 - val_accuracy: 0.1000\n",
      "Epoch 2/5\n",
      "50/50 [==============================] - 69s 1s/step - loss: 2.1305 - accuracy: 0.1920 - val_loss: 1.9153 - val_accuracy: 0.3600\n",
      "Epoch 3/5\n",
      "50/50 [==============================] - 71s 1s/step - loss: 1.8376 - accuracy: 0.3330 - val_loss: 1.8432 - val_accuracy: 0.3900\n",
      "Epoch 4/5\n",
      "50/50 [==============================] - 75s 1s/step - loss: 1.5808 - accuracy: 0.4140 - val_loss: 1.6473 - val_accuracy: 0.4000\n",
      "Epoch 5/5\n",
      "50/50 [==============================] - 77s 2s/step - loss: 1.4275 - accuracy: 0.4870 - val_loss: 1.3097 - val_accuracy: 0.5600\n"
     ]
    }
   ],
   "source": [
    "#aug = ImageDataGenerator(fill_mode=\"nearest\")\n",
    "history = model.fit(train_generator,\n",
    "                    validation_data=test_generator,\n",
    "                    steps_per_epoch=len(train_generator),\n",
    "                    validation_steps =len(test_generator),\n",
    "                    epochs=EPOCH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('modelAsli/model1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        1.0000000e+00, 2.1847597e-22]], dtype=float32)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img=image.load_img('sehat.jpg', target_size=(150, 150))\n",
    "x=image.img_to_array(img)\n",
    "x=np.expand_dims(x, axis=0)\n",
    "images = np.vstack([x])\n",
    "\n",
    "model.predict(images, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install tensorflowjs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\user\\anaconda2\\envs\\py3\\lib\\runpy.py\", line 193, in _run_module_as_main\n",
      "    \"__main__\", mod_spec)\n",
      "  File \"c:\\users\\user\\anaconda2\\envs\\py3\\lib\\runpy.py\", line 85, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"C:\\Users\\USER\\Anaconda2\\envs\\py3\\Scripts\\tensorflowjs_converter.exe\\__main__.py\", line 7, in <module>\n",
      "  File \"c:\\users\\user\\anaconda2\\envs\\py3\\lib\\site-packages\\tensorflowjs\\converters\\converter.py\", line 735, in pip_main\n",
      "    main([' '.join(sys.argv[1:])])\n",
      "  File \"c:\\users\\user\\anaconda2\\envs\\py3\\lib\\site-packages\\tensorflowjs\\converters\\converter.py\", line 739, in main\n",
      "    convert(argv[0].split(' '))\n",
      "  File \"c:\\users\\user\\anaconda2\\envs\\py3\\lib\\site-packages\\tensorflowjs\\converters\\converter.py\", line 654, in convert\n",
      "    weight_shard_size_bytes=weight_shard_size_bytes)\n",
      "  File \"c:\\users\\user\\anaconda2\\envs\\py3\\lib\\site-packages\\tensorflowjs\\converters\\converter.py\", line 74, in dispatch_keras_h5_to_tfjs_layers_model_conversion\n",
      "    raise ValueError('Nonexistent path to HDF5 file: %s' % h5_path)\n",
      "ValueError: Nonexistent path to HDF5 file: 'modelAsli/model1.h5'\n"
     ]
    }
   ],
   "source": [
    "!tensorflowjs_converter --input_format keras 'modelAsli/model1.h5' 'model'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "!tensorflowjs_converter --input_format keras D:\\POST_S1\\BANGKIT\\TomatoLeafDisease\\model.h5 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelBaru = load_model('modelAsli/model1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
